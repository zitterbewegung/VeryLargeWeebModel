# Documentation

## Technical Guides

| File | Description |
|------|-------------|
| [TRAINING.md](TRAINING.md) | **Complete training guide** (commands, configs, hardware, troubleshooting) |
| [vastai_deployment.md](vastai_deployment.md) | Vast.ai cloud deployment |
| [lambda_cloud_deployment.md](lambda_cloud_deployment.md) | Lambda Cloud deployment |
| [training_guide.md](training_guide.md) | Extended training reference (VQVAE, OccWorld integration modes) |
| [architecture_blueprint.md](architecture_blueprint.md) | System architecture and design |
| [optimization_and_debugging.md](optimization_and_debugging.md) | Performance tuning and troubleshooting |

## Media & Outreach

| File | Description |
|------|-------------|
| [blog_post.md](blog_post.md) | Technical blog post |
| [youtube_video_script.md](youtube_video_script.md) | Tutorial video script |
| [slides.md](slides.md) | Marp-compatible slide deck |
| [assets/](assets/) | Images, diagrams, and visual resources |

## Quick Start

1. Read [TRAINING.md](TRAINING.md) for the complete training workflow
2. For cloud training, see deployment guides for [Vast.ai](vastai_deployment.md) or [Lambda](lambda_cloud_deployment.md)
3. See [../ATTRIBUTION.md](../ATTRIBUTION.md) for data licensing

## External References

### Papers
- [OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving](https://arxiv.org/abs/2311.16038) (ECCV 2024)
- [nuScenes: A multimodal dataset for autonomous driving](https://arxiv.org/abs/1903.11027) (CVPR 2020)

### Repositories
- [OccWorld GitHub](https://github.com/wzzheng/OccWorld)
- [BEVFusion GitHub](https://github.com/mit-han-lab/bevfusion)
- [Occ3D GitHub](https://github.com/Tsinghua-MARS-Lab/Occ3D)

### Data Sources
- [Tokyo PLATEAU](https://www.geospatial.jp/ckan/dataset/plateau-tokyo23ku)
- [nuScenes](https://www.nuscenes.org/)
- [UAVScenes](https://github.com/iitmcvg/uavscenes)
- [Mid-Air](https://midair.ulg.ac.be/)
